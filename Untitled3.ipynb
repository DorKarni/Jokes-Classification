{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e326d8acae24764944edb990927d102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c971d379a2004bf28b736255ecde0338",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1ee1ebee0d342b7a7d5d005a9402275",
              "IPY_MODEL_b57ded6625084affb38ac10243bc7978"
            ]
          }
        },
        "c971d379a2004bf28b736255ecde0338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1ee1ebee0d342b7a7d5d005a9402275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7f55e4bd16f41a6a3f488d9885c828f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3780c648224f472a9d8d80c5c2146851"
          }
        },
        "b57ded6625084affb38ac10243bc7978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_019db83647ec4c568e8f26abe6d67a3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.19kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c665de77ec6544409f123721e92021d3"
          }
        },
        "a7f55e4bd16f41a6a3f488d9885c828f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3780c648224f472a9d8d80c5c2146851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "019db83647ec4c568e8f26abe6d67a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c665de77ec6544409f123721e92021d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35f099cb2c824711abb1dc05959498f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa8491ecc8904a2bba8b1920abb03f32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e2e147feaa04482ad1bb2fa8c971ac9",
              "IPY_MODEL_3aa8e95564cc470f9b3002a5f8a82c4b"
            ]
          }
        },
        "aa8491ecc8904a2bba8b1920abb03f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e2e147feaa04482ad1bb2fa8c971ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f16d864bc0da47a9935c9a0186957a30",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d65f39eb47c646edaa7f95ce7bf2cd2a"
          }
        },
        "3aa8e95564cc470f9b3002a5f8a82c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_074b3197c86d47a7943f18c0b3bf9834",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:13&lt;00:00, 16.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4e72cfced8f4d569e0a9a54936e3dc7"
          }
        },
        "f16d864bc0da47a9935c9a0186957a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d65f39eb47c646edaa7f95ce7bf2cd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "074b3197c86d47a7943f18c0b3bf9834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4e72cfced8f4d569e0a9a54936e3dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3f3a8e681e14dca892454b2ea4211fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20f2a5d914914938b93eb948f4b022ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0dd96e2190bf44b591a039eedc91b8ef",
              "IPY_MODEL_ffe98fe9592548f488e47abdce934477"
            ]
          }
        },
        "20f2a5d914914938b93eb948f4b022ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dd96e2190bf44b591a039eedc91b8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abf2d90bfc0542f39ae28cfe52122d50",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0cf31fdf8e445780041f877f88a360"
          }
        },
        "ffe98fe9592548f488e47abdce934477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_848ab5216f154def877c5dcff1e7cff0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:10&lt;00:00, 50.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2583017bb5ba46ac9c2400cf720eef71"
          }
        },
        "abf2d90bfc0542f39ae28cfe52122d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0cf31fdf8e445780041f877f88a360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "848ab5216f154def877c5dcff1e7cff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2583017bb5ba46ac9c2400cf720eef71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R03GiG6cm3M8"
      },
      "source": [
        "**ERNIE Install**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU-bryIhTTul",
        "outputId": "54acfb96-7878-42ee-da89-9a785b922b43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  pip install ernie"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ernie\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/780a093d4a9a38dfc866f4462155b94395b17264a794a7435777d4bbe518/ernie-0.0.33b0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.6/dist-packages (from ernie) (0.22.2.post1)\n",
            "Collecting py-cpuinfo==5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/60/63f28a5401da733043abe7053e7d9591491b4784c4f87c339bf51215aa0a/py-cpuinfo-5.0.0.tar.gz (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from ernie) (1.1.3)\n",
            "Collecting transformers==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from ernie) (2.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->ernie) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->ernie) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->ernie) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25.3->ernie) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25.3->ernie) (2.8.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->ernie) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->ernie) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->ernie) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 46.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.4.1->ernie) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/76/1f853a1ff319c173c638f38c34ebb389389253bf828e18fc4de52a2f4288/boto3-1.16.7-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.33.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.4.1->ernie) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1->ernie) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1->ernie) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1->ernie) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.4.1->ernie) (2020.6.20)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/58/64883046f9c98d9f94cc81174d0b83e0be35b8f6c252e255b709b9024ef1/botocore-1.19.7-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 44.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (3.3.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (4.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow!=2.2.0-rc0,!=2.2.0rc1,>=2.1.0->ernie) (0.4.8)\n",
            "Building wheels for collected packages: py-cpuinfo, sacremoses\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-cp36-none-any.whl size=18686 sha256=2f8adcd63fbc7ba4716b977f03ed9c95ede843f00c00c0fd79266ade0628f690\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/7e/a9/b982d0fea22b7e4ae5619de949570cde5ad55420cec16e86a5\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fbd2b6fd17f0656e9455e9836bc18a35db3ea1942450b56505dbe147d17e7c44\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built py-cpuinfo sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.7 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: py-cpuinfo, sacremoses, sentencepiece, tokenizers, jmespath, botocore, s3transfer, boto3, transformers, ernie\n",
            "Successfully installed boto3-1.16.7 botocore-1.19.7 ernie-0.0.33b0 jmespath-0.10.0 py-cpuinfo-5.0.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEjc-mFhnSFH"
      },
      "source": [
        "**Upload Database**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyfx2w7gTZts"
      },
      "source": [
        "#################################\n",
        "### Function to open CSv file ###\n",
        "#################################\n",
        "\n",
        "import csv\n",
        "\n",
        "def openCSVasList(file_name):\n",
        "    dataArr = []\n",
        "    i = 0\n",
        "    with open(file_name, 'r', encoding='latin-1') as a_file:\n",
        "        sheet_laugh = csv.reader(a_file)\n",
        "        for row in sheet_laugh:\n",
        "            # if (i % 2 == 0):                    # jump on blank rows, if there is any\n",
        "            #     dataArr.append(row)\n",
        "            #     # print(row)\n",
        "            # i += 1\n",
        "            dataArr.append(row)\n",
        "    # print(\"length of\", str, \"dataframe\", len(dataArr))\n",
        "    print(dataArr[0],dataArr[1])\n",
        "    return dataArr\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_J7bSFVII9k",
        "outputId": "71e8ba21-4d84-4cea-b048-5c1dd3ac2694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###############################################################\n",
        "### Input- open train & test dataset into panda's DataFrame ###\n",
        "###############################################################\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "\n",
        "train_file_name = '/content/all_text_wth_speaker_50_50_s_j_80.csv'\n",
        "Corpus_train = pd.DataFrame(openCSVasList(train_file_name))\n",
        "\n",
        "test_file_name = '/content/all_text_wth_speaker_50_50_s_j_20.csv'\n",
        "Corpus_test = pd.DataFrame(openCSVasList(test_file_name))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"ï»¿Penny -  Let's see To continue on your quest leave no stone unturned Ooh\", 'SENTENCE'] [\"Sheldon -  Interesting So it went beyond the mere fact of coitus to a blow by blow as it were Pun intended I'm sorry What pun\", 'JOKE']\n",
            "['ï»¿Sheldon -  So your mirth is merely a discharge of nervous energy', 'SENTENCE'] ['Leonard -  So much for our friendship with Sheldon', 'SENTENCE']\n",
            "train 3610 \n",
            "test 903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZhZn4TCrMRg",
        "outputId": "98c1750c-1eb1-440c-e119-cc80572c8510",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  #########################################\n",
        "  ### Labelize the data as integers 1,0 ###\n",
        "  #########################################\n",
        "\n",
        "  label1 = Corpus_train.iat[0,1]\n",
        "  # label1 = 'SENTENCE'\n",
        "  i=1\n",
        "  while (Corpus_train.iloc[i,1] == label1): i+=1\n",
        "  label0 = Corpus_train.iloc[i,1] \n",
        "\n",
        "  Corpus_train[1] = (Corpus_train[1] == label1).astype(int)\n",
        "  Corpus_test[1] = (Corpus_test[1] == label1).astype(int)\n",
        "  print(\"label1: \", label1, \"\\tlabel0: \", label0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label1:  SENTENCE \tlabel0:  JOKE\n",
            "ï»¿Penny -  Let's see To continue on your quest leave no stone unturned Ooh \n",
            " Sheldon -  Interesting that you ask The Coast Starlight recently added the refurbished Pacific Parlour Car Built in 1956 and originally known as the Santa Fe Lounge Car the lower level is a theater and the upper level is a bar that offers wine tastings if you're going as far as Portland \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgVSjvQfUuQF"
      },
      "source": [
        "###########################################\n",
        "### From soft decision to hard decision ###\n",
        "###########################################\n",
        "\n",
        "def probabilitiesTodecisions(probabilities_list):\n",
        "  decisions = []\n",
        "  for i in range(len(probabilities_list)):\n",
        "    if probabilities_list[i][0] >=0.5:\n",
        "      decisions.append(0)\n",
        "    else:\n",
        "      decisions.append(1)\n",
        "    # print(probabilities_list[i], \"\\t\", decisions[i])\n",
        "  return decisions\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgHpUqIzpuz3"
      },
      "source": [
        "######################\n",
        "### check accuracy ###\n",
        "######################\n",
        "\n",
        "def checkAccuracy(prediction_labels,Test_labels):\n",
        "  label_1_counter = 0\n",
        "  label_1_match = 0\n",
        "  label_0_counter = 0\n",
        "  label_0_match = 0\n",
        "  label_match= 0\n",
        "  \n",
        "  for i in range(len(prediction_labels)):\n",
        "      if_correct = False                        ### add\n",
        "      if(Test_labels.iloc[i,1] == 1):   # If the original label is '1'\n",
        "          label_1_counter += 1\n",
        "          if(prediction_labels[i] == Test_labels.iloc[i,1]):  # And if the prediction label is the same\n",
        "              label_1_match += 1\n",
        "\n",
        "              # print(Test_labels.iloc[i,0])    ### add\n",
        "              if_correct = True                 ### add\n",
        "\n",
        "      elif(Test_labels.iloc[i,1] == 0): # If the original label is '0'\n",
        "          label_0_counter += 1\n",
        "          if(prediction_labels[i] == Test_labels.iloc[i,1]):\n",
        "              label_0_match += 1\n",
        "\n",
        "              # print(Test_labels.iloc[i,0])    ### add\n",
        "              if_correct = True                 ### add\n",
        "\n",
        "      ### add\n",
        "      # if (if_correct == True):\n",
        "      #   print(\"true: \", Test_labels.iloc[i,1], \"prediction: \", prediction_labels[i], \"line number: \", i)\n",
        "      # else:\n",
        "      #   print(\"true: \", Test_labels.iloc[i,1], \"prediction: \", prediction_labels[i])\n",
        "\n",
        "  # Printing the results\n",
        "  print(\"number of matches \\n*label 1* \\t\",label_1_match ,\"/\", label_1_counter,\n",
        "        \"\\n*label 0* \\t\",label_0_match ,\"/\", label_0_counter,)\n",
        "  label_match = label_0_match + label_1_match\n",
        "  accuracy = (label_match)*100/(len(prediction_labels))\n",
        "  print(\"check accuracy\\t\", accuracy)\n",
        "  \n",
        "\n",
        "\n",
        "  # Save the results as CSV file\n",
        "  with open(\"/content/a.csv\", 'w') as csvfile:\n",
        "    table_write = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    table_write.writerow(['','Test_Y - reality', 'predictions_NN'])\n",
        "    for i in range(len(prediction_labels)):\n",
        "      if (prediction_labels[i] == Test_labels.iloc[i,1]):\n",
        "        table_write.writerow([Test_labels.iloc[i,0] ,Test_labels.iloc[i,1], prediction_labels[i], \"match\"])\n",
        "      else:\n",
        "        table_write.writerow([Test_labels.iloc[i,0] ,Test_labels.iloc[i,1], prediction_labels[i]])\n",
        "          \n",
        "        # if (prediction_labels[i] == Test_labels.iloc[i,1]):\n",
        "        #     if (prediction_labels[i] == 1):\n",
        "        #       table_write.writerow([prediction_labels[i] ,Test_labels.iloc[i,1], \"1 match\"])\n",
        "        #     elif (prediction_labels[i] == 0):\n",
        "        #         table_write.writerow([prediction_labels[i], Test_labels.iloc[i,1], \"0 match\"])\n",
        "        # else:\n",
        "        #     table_write.writerow([prediction_labels[i], Test_labels.iloc[i,1]])\n",
        "\n",
        "  return accuracy, label_1_match/label_1_counter, label_0_match/label_0_counter\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfax9FT_UBhi"
      },
      "source": [
        "###########################################\n",
        "### Save the test output for the graphs ###\n",
        "###########################################\n",
        "\n",
        "def append_3_list(model_vs_epochs_,accuracy_, match1_, match0_):\n",
        "  model_vs_epochs_[0].append(accuracy_)\n",
        "  model_vs_epochs_[1].append(match1_)\n",
        "  model_vs_epochs_[2].append(match0_)\n",
        "  return model_vs_epochs_\n",
        "\n",
        "model_vs_epochs = [[],[],[]]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaM2LJ-vnkeH"
      },
      "source": [
        "**Running Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ_cCPI_ZtTS",
        "outputId": "c66a6d71-e395-41dd-9c52-f2992ede975a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "0e326d8acae24764944edb990927d102",
            "c971d379a2004bf28b736255ecde0338",
            "e1ee1ebee0d342b7a7d5d005a9402275",
            "b57ded6625084affb38ac10243bc7978",
            "a7f55e4bd16f41a6a3f488d9885c828f",
            "3780c648224f472a9d8d80c5c2146851",
            "019db83647ec4c568e8f26abe6d67a3e",
            "c665de77ec6544409f123721e92021d3",
            "35f099cb2c824711abb1dc05959498f9",
            "aa8491ecc8904a2bba8b1920abb03f32",
            "1e2e147feaa04482ad1bb2fa8c971ac9",
            "3aa8e95564cc470f9b3002a5f8a82c4b",
            "f16d864bc0da47a9935c9a0186957a30",
            "d65f39eb47c646edaa7f95ce7bf2cd2a",
            "074b3197c86d47a7943f18c0b3bf9834",
            "b4e72cfced8f4d569e0a9a54936e3dc7",
            "d3f3a8e681e14dca892454b2ea4211fe",
            "20f2a5d914914938b93eb948f4b022ee",
            "0dd96e2190bf44b591a039eedc91b8ef",
            "ffe98fe9592548f488e47abdce934477",
            "abf2d90bfc0542f39ae28cfe52122d50",
            "3d0cf31fdf8e445780041f877f88a360",
            "848ab5216f154def877c5dcff1e7cff0",
            "2583017bb5ba46ac9c2400cf720eef71"
          ]
        }
      },
      "source": [
        "###################################################\n",
        "### Run the neural network on the train dataset ###\n",
        "###################################################\n",
        "\n",
        "from ernie import SentenceClassifier, Models\n",
        "\n",
        "# 1 epochs\n",
        "classifier1 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2) # Initialize the model\n",
        "classifier1.load_dataset(Corpus_train, validation_split=0.2)  # Load the dataset for a pre-train\n",
        "classifier1.fine_tune(epochs=1, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64) # learning stage\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e326d8acae24764944edb990927d102",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35f099cb2c824711abb1dc05959498f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3f3a8e681e14dca892454b2ea4211fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "90/90 [==============================] - 42s 465ms/step - loss: 0.6991 - accuracy: 0.5010 - val_loss: 0.6846 - val_accuracy: 0.5355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiYDXgq_Zz_7",
        "outputId": "160c0010-895b-477a-c02f-9ad2499cd975",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probabilities1 = list(classifier1.predict(Corpus_test[0]))\n",
        "\n",
        "decisions1 = probabilitiesTodecisions(probabilities1)\n",
        "\n",
        "accuracy1, match1_1, match0_1 = checkAccuracy(decisions1, Corpus_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of matches \n",
            "*label 1* \t 410 / 433 \n",
            "*label 0* \t 46 / 470\n",
            "check accuracy\t 50.498338870431894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sbkyQaBUNwq"
      },
      "source": [
        "model_vs_epochs = append_3_list(model_vs_epochs, accuracy1, match1_1, match0_1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BE_iekKRELm",
        "outputId": "ae42cb15-62f5-4582-c602-2551bc8b041e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2 epochs\n",
        "classifier2 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier2.load_dataset(Corpus_train, validation_split=0.2)\n",
        "classifier2.fine_tune(epochs=2, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 44s 487ms/step - loss: 0.6914 - accuracy: 0.5267 - val_loss: 0.6807 - val_accuracy: 0.5526\n",
            "90/90 [==============================] - 43s 482ms/step - loss: 0.6560 - accuracy: 0.6139 - val_loss: 0.6686 - val_accuracy: 0.5838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrD-tBf9Yn38",
        "outputId": "01dcbf26-664f-4736-fbc5-63bf993ff257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probabilities2 = list(classifier2.predict(Corpus_test[0]))\n",
        "\n",
        "decisions2 = probabilitiesTodecisions(probabilities2)\n",
        "\n",
        "accuracy2, match1_2, match0_2 = checkAccuracy(decisions2, Corpus_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of matches \n",
            "*label 1* \t 212 / 433 \n",
            "*label 0* \t 333 / 470\n",
            "check accuracy\t 60.35437430786268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1LdCFH4UaSw"
      },
      "source": [
        "  model_vs_epochs = append_3_list(model_vs_epochs, accuracy2, match1_2, match0_2)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABixdvCqY3qq",
        "outputId": "0259cab7-ca8a-464f-d777-09dd7e624030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 3 epochs\n",
        "classifier3 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier3.load_dataset(Corpus_train, validation_split=0.2)\n",
        "classifier3.fine_tune(epochs=3, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 46s 507ms/step - loss: 0.6900 - accuracy: 0.5278 - val_loss: 0.6947 - val_accuracy: 0.5170\n",
            "90/90 [==============================] - 43s 473ms/step - loss: 0.6562 - accuracy: 0.6118 - val_loss: 0.6701 - val_accuracy: 0.5795\n",
            "90/90 [==============================] - 43s 476ms/step - loss: 0.5524 - accuracy: 0.7212 - val_loss: 0.7878 - val_accuracy: 0.5753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Cl2y0HpLiT",
        "outputId": "0936233f-e269-486c-c504-856434217c7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probabilities3 = list(classifier3.predict(Corpus_test[0]))  \n",
        "\n",
        "decisions3 = probabilitiesTodecisions(probabilities3)\n",
        "\n",
        "accuracy3, match1_3, match0_3 = checkAccuracy(decisions3, Corpus_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of matches \n",
            "*label 1* \t 329 / 433 \n",
            "*label 0* \t 187 / 470\n",
            "check accuracy\t 57.142857142857146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxFMCAwFUsNR"
      },
      "source": [
        "model_vs_epochs = append_3_list(model_vs_epochs, accuracy3, match1_3, match0_3)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9278c8WCBrs3",
        "outputId": "2957f8f6-6c87-4823-ff86-73f27582206c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4 epochs\n",
        "classifier4 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier4.load_dataset(Corpus_train, validation_split=0.2)\n",
        "classifier4.fine_tune(epochs=4, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 46s 510ms/step - loss: 0.6872 - accuracy: 0.5385 - val_loss: 0.6847 - val_accuracy: 0.5554\n",
            "90/90 [==============================] - 42s 471ms/step - loss: 0.6478 - accuracy: 0.6208 - val_loss: 0.7585 - val_accuracy: 0.5412\n",
            "90/90 [==============================] - 43s 477ms/step - loss: 0.5532 - accuracy: 0.7247 - val_loss: 0.7673 - val_accuracy: 0.5369\n",
            "90/90 [==============================] - 43s 474ms/step - loss: 0.3444 - accuracy: 0.8653 - val_loss: 0.9607 - val_accuracy: 0.5497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRVD4NUB1Rg",
        "outputId": "80032a79-b716-42e5-a291-0adef49ba2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "probabilities4 = list(classifier4.predict(Corpus_test[0]))\n",
        "\n",
        "decisions4 = probabilitiesTodecisions(probabilities4)\n",
        "\n",
        "accuracy4, match1_4, match0_4 = checkAccuracy(decisions4, Corpus_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of matches \n",
            "*label 1* \t 286 / 433 \n",
            "*label 0* \t 210 / 470\n",
            "check accuracy\t 54.928017718715395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKj18fBvVsNw"
      },
      "source": [
        "model_vs_epochs = append_3_list(model_vs_epochs, accuracy4, match1_4, match0_4)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-lVM1Py2TdL",
        "outputId": "dbcf6795-75ae-45ca-8090-a280539bdca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# 5 epochs\n",
        "classifier5 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier5.load_dataset(Corpus_train, validation_split=0.2)\n",
        "classifier5.fine_tune(epochs=5, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 46s 511ms/step - loss: 0.6906 - accuracy: 0.5337 - val_loss: 0.7005 - val_accuracy: 0.5355\n",
            "90/90 [==============================] - 42s 471ms/step - loss: 0.6527 - accuracy: 0.6132 - val_loss: 0.6984 - val_accuracy: 0.5398\n",
            "29/90 [========>.....................] - ETA: 26s - loss: 0.5648 - accuracy: 0.7403"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b0697ed6eadb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBertBaseUncased\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ernie/ernie.py\u001b[0m in \u001b[0;36mfine_tune\u001b[0;34m(self, epochs, learning_rate, epsilon, clipnorm, optimizer_function, optimizer_kwargs, loss_function, loss_kwargs, accuracy_function, accuracy_kwargs, training_batch_size, validation_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# The fine-tuned model does not have the same input interface after being\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV5l97S7Dkvf"
      },
      "source": [
        "probabilities5 = list(classifier5.predict(Corpus_test[0]))\n",
        "\n",
        "decisions5 = probabilitiesTodecisions(probabilities5)\n",
        "\n",
        "accuracy5, match1_5, match0_5 = checkAccuracy(decisions5, Corpus_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmivgduYV0dG"
      },
      "source": [
        "model_vs_epochs = append_3_list(model_vs_epochs, accuracy5, match1_5, match0_5)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAvu8QJn38u"
      },
      "source": [
        "**Plotting the Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr1RaIa6XXfC"
      },
      "source": [
        "for i in range(len(model_vs_epochs[0])):\n",
        "  model_vs_epochs[0][i] = model_vs_epochs[0][i]/100\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-oEJVdXWXjP"
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "\n",
        "# All 3 datas\n",
        "plot.figure(figsize=(10,10))\n",
        "plot.subplot(211)\n",
        "plot.plot(model_vs_epochs[0])   # accuracy\n",
        "plot.plot(model_vs_epochs[1])   # matches of label 1\n",
        "plot.plot(model_vs_epochs[2])   # matches of label 0\n",
        "plot.title('Model fit')\n",
        "plot.ylabel('Fit')\n",
        "plot.xlabel('Epoch')\n",
        "plot.legend(['Accuracy', 'Label 1', 'Label 0'], loc='upper left')\n",
        "\n",
        "# Only accuracy\n",
        "plot.subplot(212)\n",
        "plot.plot(model_vs_epochs[0])   # accuracy\n",
        "plot.title('Model accuracy')\n",
        "plot.ylabel('Accuracy')\n",
        "plot.xlabel('Epoch')\n",
        "\n",
        "plot.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLqW23cLc57g"
      },
      "source": [
        "# 10 epochs\n",
        "classifier10 = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier10.load_dataset(Corpus_train, validation_split=0.2)\n",
        "classifier10.fine_tune(epochs=17, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vub3zzWsc8EV"
      },
      "source": [
        "probabilities10 = list(classifier10.predict(Corpus_test[0]))\n",
        "\n",
        "decisions10 = probabilitiesTodecisions(probabilities10)\n",
        "\n",
        "accuracy10, match1_10, match0_10 = checkAccuracy(decisions10, Corpus_test)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3772NAg8z6oA"
      },
      "source": [
        "from ernie import SentenceClassifier, Models\n",
        "\n",
        "model_epochs = [[],[],[]]\n",
        "\n",
        "# testing\n",
        "classifier_t = SentenceClassifier(model_name=Models.BertBaseUncased, max_length=64, labels_no=2)\n",
        "classifier_t.load_dataset(Corpus_train, validation_split=0.2)\n",
        "for i in range(10): \n",
        "  print(\"\\n\\n\", \"num of epochs:   \", i+1)\n",
        "  classifier_t.fine_tune(epochs=1, learning_rate=2e-5, training_batch_size=32, validation_batch_size=64)\n",
        "  probabilities_t = list(classifier_t.predict(Corpus_test[0]))\n",
        "  decisions_t = probabilitiesTodecisions(probabilities_t)\n",
        "  accuracy_t, match1_t, match0_t = checkAccuracy(decisions_t, Corpus_test)\n",
        "  model_epochs = append_3_list(model_epochs, accuracy_t, match1_t, match0_t)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2UEWq8ZfxIS"
      },
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "\n",
        "# All 3 datas\n",
        "plot.figure(figsize=(10,10))\n",
        "plot.subplot(211)\n",
        "plot.plot(model_epochs[0])   # accuracy\n",
        "plot.plot(model_epochs[1])   # matches of label 1\n",
        "plot.plot(model_epochs[2])   # matches of label 0\n",
        "plot.title('Model fit')\n",
        "plot.ylabel('Fit')\n",
        "plot.xlabel('Epoch')\n",
        "plot.legend(['Accuracy', 'Label 1', 'Label 0'], loc='upper left')\n",
        "\n",
        "# Only accuracy\n",
        "plot.subplot(212)\n",
        "plot.plot(model_epochs[0])   # accuracy\n",
        "plot.title('Model accuracy')\n",
        "plot.ylabel('Accuracy')\n",
        "plot.xlabel('Epoch')\n",
        "\n",
        "plot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z2Z2ssHMnUO"
      },
      "source": [
        "# def encodeLable(df):\n",
        "#   label0 = df.iat[0,1]\n",
        "#   label1 = df.iat[50,1]\n",
        "#   print(\"label0 \", label0, \"\\tlabel1 \", label1)\n",
        "#   for index in range(len(Corpus_test1)):\n",
        "#     if df.iloc[index, 1] == label0:\n",
        "#       print(df.iloc[index, 1] , label0)\n",
        "#       df.iloc[index, 1] = label0\n",
        "#     else:\n",
        "#       print(df.iloc[index, 1] , label1)\n",
        "#       df.iloc[index, 1] = label1\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# # check labeling\n",
        "# train_file_name1 = '/content/all_text_2400J4000S_9.6_rand_0.8.csv'\n",
        "# Corpus_train1 = pd.DataFrame(openCSVasList(train_file_name1))\n",
        "# for i in range(len( Corpus_train1)):\n",
        "#   print(\"sourse: \", Corpus_train1.iloc[i,1], \"\\t labeled: \", Corpus_train.iloc[i,1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Check the accuracy on the test dataset\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# probabilities = list(classifier.predict(Corpus_test[0]))\n",
        "# avarege = 0\n",
        "# for i in range(len(probabilities)):\n",
        "#   avarege += probabilities[i][0]\n",
        "#   # print(probabilities[i][0])\n",
        "# print(\"avarege\", avarege/len(probabilities))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScpqHqWVqWOY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}